# 真实I/O场景模拟
import asyncio
import aiohttp
import time
import threading
import multiprocessing as mp
import concurrent.futures
from typing import Dict, Any, List
import statistics
import json
from dataclasses import dataclass
from contextlib import contextmanager
import requests

@dataclass
class PerformanceResult:
    """性能测试结果数据类"""
    scenario: str
    implementation: str
    total_time: float
    throughput: float  # requests per second
    latency_mean: float
    latency_std: float
    memory_usage: Dict[str, float]
    cpu_usage: Dict[str, float]
    details: Dict[str, Any] = None

class RealisticIOLoadGenerator:
    """真实的I/O负载生成器"""
    
    def __init__(self):
        self.base_url = "https://httpbin.org"
        self.endpoints = [
            "/get", 
            "/delay/1", 
            "/status/200",
            "/headers",
            "/user-agent"
        ]
    
    def get_random_endpoint(self) -> str:
        """获取随机endpoint"""
        import random
        return f"{self.base_url}{random.choice(self.endpoints)}"
    
    def sync_http_request(self, task_id: int) -> Dict[str, Any]:
        """同步HTTP请求"""
        start_time = time.time()
        url = self.get_random_endpoint()
        
        try:
            response = requests.get(url, timeout=5)
            duration = time.time() - start_time
            
            return {
                'task_id': task_id,
                'url': url,
                'status': response.status_code,
                'duration': duration,
                'timestamp': time.time(),
                'success': True
            }
        except Exception as e:
            return {
                'task_id': task_id,
                'url': url,
                'error': str(e),
                'duration': time.time() - start_time,
                'success': False
            }
    
    async def async_http_request(self, session: aiohttp.ClientSession, task_id: int) -> Dict[str, Any]:
        """异步HTTP请求"""
        start_time = time.time()
        url = self.get_random_endpoint()
        
        try:
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as response:
                duration = time.time() - start_time
                
                return {
                    'task_id': task_id,
                    'url': url,
                    'status': response.status,
                    'duration': duration,
                    'timestamp': time.time(),
                    'success': True
                }
        except Exception as e:
            return {
                'task_id': task_id,
                'url': url,
                'error': str(e),
                'duration': time.time() - start_time,
                'success': False
            }
    
    def thread_http_request(self, task_id: int) -> Dict[str, Any]:
        """线程HTTP请求"""
        return self.sync_http_request(task_id)
    
    def process_http_request(self, task_id: int) -> Dict[str, Any]:
        """进程HTTP请求"""
        return self.sync_http_request(task_id)

class PerformanceBenchmark:
    """性能基准测试框架"""
    
    def __init__(self, test_duration: float = 10.0):
        self.test_duration = test_duration
        self.results: List[PerformanceResult] = []
        self.load_generator = RealisticIOLoadGenerator()
    
    @contextmanager
    def timer(self):
        """精确计时上下文管理器"""
        start_time = time.perf_counter()
        yield lambda: time.perf_counter() - start_time
    
    def measure_resources(self) -> Dict[str, float]:
        """测量资源使用情况"""
        try:
            import psutil
            process = psutil.Process()
            
            # 内存使用
            memory_info = process.memory_info()
            memory_mb = memory_info.rss / 1024 / 1024
            
            # CPU使用
            cpu_percent = process.cpu_percent()
            
            return {
                'peak': memory_mb,
                'average': memory_mb,
                'cpu_peak': cpu_percent,
                'cpu_average': cpu_percent
            }
        except ImportError:
            # 模拟值
            import random
            return {
                'peak': round(random.uniform(100, 500), 2),
                'average': round(random.uniform(80, 400), 2),
                'cpu_peak': round(random.uniform(10, 80), 1),
                'cpu_average': round(random.uniform(5, 50), 1)
            }
    
    def run_sync_benchmark(self) -> PerformanceResult:
        """运行同步基准测试"""
        print("运行同步基准测试...")
        
        with self.timer() as get_duration:
            results = []
            start_time = time.time()
            
            while time.time() - start_time < self.test_duration:
                result = self.load_generator.sync_http_request(len(results))
                results.append(result)
        
        total_time = get_duration()
        successful_results = [r for r in results if r['success']]
        
        # 计算延迟统计
        if successful_results:
            latencies = [r['duration'] for r in successful_results]
            latency_mean = statistics.mean(latencies)
            latency_std = statistics.stdev(latencies) if len(latencies) > 1 else 0
        else:
            latency_mean = 0
            latency_std = 0
        
        # 测量资源使用
        resources = self.measure_resources()
        
        return PerformanceResult(
            scenario="同步I/O",
            implementation="requests库",
            total_time=total_time,
            throughput=len(successful_results) / total_time if total_time > 0 else 0,
            latency_mean=latency_mean,
            latency_std=latency_std,
            memory_usage=resources,
            cpu_usage=resources,
            details={'total_requests': len(results), 'successful_requests': len(successful_results)}
        )
    
    async def run_async_benchmark(self) -> PerformanceResult:
        """运行异步基准测试"""
        print("运行异步基准测试...")
        
        with self.timer() as get_duration:
            results = []
            start_time = time.time()
            
            async with aiohttp.ClientSession() as session:
                tasks = []
                
                while time.time() - start_time < self.test_duration:
                    task = self.load_generator.async_http_request(session, len(results))
                    tasks.append(task)
                    
                    # 限制并发数
                    if len(tasks) >= 4:  # 统一并行数量为4个
                        batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                        results.extend([r if not isinstance(r, Exception) else {
                            'task_id': len(results) + i,
                            'error': str(r),
                            'success': False,
                            'duration': 0
                        } for i, r in enumerate(batch_results)])
                        tasks = []
                
                # 处理剩余任务
                if tasks:
                    batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                    results.extend([r if not isinstance(r, Exception) else {
                        'task_id': len(results) + i,
                        'error': str(r),
                        'success': False,
                        'duration': 0
                    } for i, r in enumerate(batch_results)])
        
        total_time = get_duration()
        successful_results = [r for r in results if isinstance(r, dict) and r.get('success', False)]
        
        # 计算延迟统计
        if successful_results:
            latencies = [r['duration'] for r in successful_results]
            latency_mean = statistics.mean(latencies)
            latency_std = statistics.stdev(latencies) if len(latencies) > 1 else 0
        else:
            latency_mean = 0
            latency_std = 0
        
        # 测量资源使用
        resources = self.measure_resources()
        
        return PerformanceResult(
            scenario="异步I/O",
            implementation="aiohttp库",
            total_time=total_time,
            throughput=len(successful_results) / total_time if total_time > 0 else 0,
            latency_mean=latency_mean,
            latency_std=latency_std,
            memory_usage=resources,
            cpu_usage=resources,
            details={'total_requests': len(results), 'successful_requests': len(successful_results)}
        )
    
    def run_thread_benchmark(self) -> PerformanceResult:
        """运行多线程基准测试"""
        print("运行多线程基准测试...")
        
        with self.timer() as get_duration:
            results = []
            start_time = time.time()
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:  # 统一并行数量为4个
                futures = []
                
                while time.time() - start_time < self.test_duration:
                    future = executor.submit(self.load_generator.thread_http_request, len(futures))
                    futures.append(future)
                    
                    # 限制并发数
                    if len(futures) >= 4:  # 统一并行数量为4个
                        for future in concurrent.futures.as_completed(futures):
                            try:
                                result = future.result()
                                results.append(result)
                            except Exception as e:
                                results.append({
                                    'task_id': len(results),
                                    'error': str(e),
                                    'success': False,
                                    'duration': 0
                                })
                        futures = []
                
                # 处理剩余任务
                for future in concurrent.futures.as_completed(futures):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        results.append({
                            'task_id': len(results),
                            'error': str(e),
                            'success': False,
                            'duration': 0
                        })
        
        total_time = get_duration()
        successful_results = [r for r in results if r.get('success', False)]
        
        # 计算延迟统计
        if successful_results:
            latencies = [r['duration'] for r in successful_results]
            latency_mean = statistics.mean(latencies)
            latency_std = statistics.stdev(latencies) if len(latencies) > 1 else 0
        else:
            latency_mean = 0
            latency_std = 0
        
        # 测量资源使用
        resources = self.measure_resources()
        
        return PerformanceResult(
            scenario="多线程I/O",
            implementation="ThreadPoolExecutor",
            total_time=total_time,
            throughput=len(successful_results) / total_time if total_time > 0 else 0,
            latency_mean=latency_mean,
            latency_std=latency_std,
            memory_usage=resources,
            cpu_usage=resources,
            details={'total_requests': len(results), 'successful_requests': len(successful_results)}
        )
    
    def run_benchmark(self):
        """运行完整的基准测试套件"""
        print(f"开始性能基准测试，持续时间: {self.test_duration}秒")
        print("=" * 60)
        
        # 运行同步测试
        sync_result = self.run_sync_benchmark()
        self.results.append(sync_result)
        
        # 运行异步测试
        async_result = asyncio.run(self.run_async_benchmark())
        self.results.append(async_result)
        
        # 运行多线程测试
        thread_result = self.run_thread_benchmark()
        self.results.append(thread_result)
        
        # 显示结果
        self.display_results()
    
    def display_results(self):
        """显示测试结果"""
        print("\n" + "=" * 60)
        print("性能基准测试结果")
        print("=" * 60)
        
        for i, result in enumerate(self.results, 1):
            print(f"\n测试 {i}: {result.scenario}")
            print(f"实现: {result.implementation}")
            print(f"总时间: {result.total_time:.2f}秒")
            print(f"吞吐量: {result.throughput:.2f} 请求/秒")
            print(f"平均延迟: {result.latency_mean:.3f}秒")
            print(f"延迟标准差: {result.latency_std:.3f}秒")
            print(f"内存峰值: {result.memory_usage['peak']:.1f}MB")
            print(f"CPU峰值: {result.cpu_usage['cpu_peak']:.1f}%")
            
            if result.details:
                total = result.details.get('total_requests', 0)
                successful = result.details.get('successful_requests', 0)
                success_rate = (successful / total * 100) if total > 0 else 0
                print(f"成功率: {success_rate:.1f}% ({successful}/{total})")
        
        print("\n" + "=" * 60)
        print("测试完成！")

if __name__ == "__main__":
    # 运行基准测试
    benchmark = PerformanceBenchmark(test_duration=10.0)
    benchmark.run_benchmark()