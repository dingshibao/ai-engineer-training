import asyncio
import json
import logging
import numpy as np
import os
import dashscope
import requests
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional, Any
from neo4j import GraphDatabase
from neo4j_graphrag.llm import OpenAILLM
import re
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import jieba
import jieba.analyse

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è®¾ç½®é€šä¹‰åƒé—®APIå¯†é’¥
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY", "your-api-key-here")

@dataclass
class Entity:
    name: str
    type: str
    confidence: float = 1.0

@dataclass  
class Relationship:
    source: str
    target: str
    type: str
    confidence: float = 1.0

@dataclass
class Document:
    id: str
    content: str
    metadata: Dict[str, Any]
    embedding: Optional[np.ndarray] = None

@dataclass
class RetrievalResult:
    document: Document
    score: float
    source: str  # 'vector' or 'keyword' or 'graph'

@dataclass
class GraphResult:
    entities: List[str]
    relationships: List[Dict]
    confidence: float
    reasoning_path: List[str]

class QwenEmbedding:
    """é€šä¹‰åƒé—®æ–‡æœ¬åµŒå…¥æœåŠ¡"""
    
    def __init__(self, model_name="text-embedding-v3"):
        self.model_name = model_name
        
    def encode(self, texts):
        """ç¼–ç æ–‡æœ¬ä¸ºå‘é‡"""
        if isinstance(texts, str):
            texts = [texts]
            
        try:
            from dashscope import TextEmbedding
            
            response = TextEmbedding.call(
                model=self.model_name,
                input=texts
            )
            
            if response.status_code == 200:
                embeddings = []
                for output in response.output['embeddings']:
                    embeddings.append(np.array(output['embedding']))
                
                return embeddings[0] if len(embeddings) == 1 else embeddings
            else:
                logger.error(f"é€šä¹‰åƒé—®embeddingè°ƒç”¨å¤±è´¥: {response}")
                # é™çº§åˆ°æœ¬åœ°æ¨¡åž‹
                fallback_model = SentenceTransformer('all-MiniLM-L6-v2')
                return fallback_model.encode(texts)
                
        except Exception as e:
            logger.error(f"é€šä¹‰åƒé—®embeddingå¼‚å¸¸: {e}")
            # é™çº§åˆ°æœ¬åœ°æ¨¡åž‹
            fallback_model = SentenceTransformer('all-MiniLM-L6-v2')
            return fallback_model.encode(texts)

class ImprovedHybridRAGSystem:
    """
    æ”¹è¿›çš„æ··åˆRAGç³»ç»Ÿ
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. ä½¿ç”¨é€šä¹‰åƒé—®text-embedding-v3æå‡ä¸­æ–‡ç†è§£
    2. ä¼˜åŒ–å…³é”®è¯æå–ï¼Œä½¿ç”¨jiebaåˆ†è¯
    3. æ”¹è¿›ç›¸ä¼¼åº¦è®¡ç®—å’Œé˜ˆå€¼è®¾ç½®
    4. å¢žå¼ºå›¾è°±æŽ¨ç†é€»è¾‘
    5. æ·»åŠ å‘é‡æ•°æ®åº“å†…ç½®å‡½æ•°å¯¹æ¯”æµ‹è¯•
    """
    
    def __init__(self, neo4j_driver, llm_json, llm_text, use_qwen_embedding=True):
        self.driver = neo4j_driver
        self.llm_json = llm_json  # ç»“æž„åŒ–è¾“å‡º
        self.llm_text = llm_text  # æ–‡æœ¬ç”Ÿæˆ
        
        # åˆå§‹åŒ–å‘é‡æ¨¡åž‹
        if use_qwen_embedding:
            self.embedding_model = QwenEmbedding("text-embedding-v3")
            logger.info("âœ… ä½¿ç”¨é€šä¹‰åƒé—®text-embedding-v3æ¨¡åž‹")
        else:
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("âœ… ä½¿ç”¨SentenceTransformeræ¨¡åž‹")
        
        # æ–‡æ¡£å­˜å‚¨
        self.documents: List[Document] = []
        
        # å…³é”®è¯ç´¢å¼•
        self.keyword_index = {
            'terms': {},  # term -> [doc_indices]
            'doc_terms': {}  # doc_id -> [terms]
        }
        
        # é…ç½®å‚æ•° - é™ä½Žé˜ˆå€¼æå‡å¬å›žçŽ‡
        self.config = {
            'confidence_threshold': 0.3,  # é™ä½Žç½®ä¿¡åº¦é˜ˆå€¼
            'max_retrieval_results': 10,   # å¢žåŠ æ£€ç´¢ç»“æžœæ•°
            'vector_weight': 0.5,         # æé«˜å‘é‡æ£€ç´¢æƒé‡
            'keyword_weight': 0.3,        # å…³é”®è¯æ£€ç´¢æƒé‡  
            'graph_weight': 0.2,          # å›¾è°±æŽ¨ç†æƒé‡
            'error_propagation_threshold': 0.3,  # é™ä½Žé”™è¯¯ä¼ æ’­é˜ˆå€¼
            'keyword_threshold': 0.1      # å…³é”®è¯åŒ¹é…é˜ˆå€¼
        }
    
    def clear_vector_database(self):
        """æ¸…ç†å‘é‡æ•°æ®åº“ï¼Œåˆ é™¤æ‰€æœ‰æ–‡æ¡£å’ŒåµŒå…¥"""
        self.documents = []
        self.keyword_index = {
            'terms': {},  # term -> [doc_indices]
            'doc_terms': {}  # doc_id -> [terms]
        }
        logger.info("âœ… å‘é‡æ•°æ®åº“å·²æ¸…ç†")
    
    def clear_graph_database(self):
        """æ¸…ç†å›¾æ•°æ®åº“ï¼Œåˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»"""
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
        logger.info("âœ… å›¾æ•°æ®åº“å·²æ¸…ç†")
    
    def clear_all_databases(self):
        """æ¸…ç†æ‰€æœ‰æ•°æ®åº“"""
        self.clear_vector_database()
        self.clear_graph_database()
        logger.info("ðŸ§¹ æ‰€æœ‰æ•°æ®åº“å·²æ¸…ç†å®Œæˆ")
    
    def load_data_from_file(self, file_path: str) -> str:
        """ä»Žæ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return ""
    
    async def process_text_to_documents(self, raw_text: str) -> List[Dict[str, Any]]:
        """å°†åŽŸå§‹æ–‡æœ¬å¤„ç†ä¸ºæ–‡æ¡£"""
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = [p.strip() for p in raw_text.split('\n') if p.strip()]
        
        documents = []
        for i, paragraph in enumerate(paragraphs):
            if len(paragraph) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
                documents.append({
                    'id': f'doc_{i}',
                    'content': paragraph,
                    'metadata': {'source': 'file', 'paragraph_id': i}
                })
        
        return documents
    
    async def extract_relationships_from_text(self, raw_text: str) -> List[Tuple[str, str]]:
        """ä»Žæ–‡æœ¬ä¸­æå–å…³ç³»"""
        prompt = f"""
        ä»Žä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…¬å¸æŽ§è‚¡å…³ç³»ï¼Œè¿”å›žJSONæ ¼å¼ï¼š
        
        æ–‡æœ¬ï¼š{raw_text}
        
        è¿”å›žæ ¼å¼ï¼š
        {{
            "relationships": [
                {{"source": "å…¬å¸A", "target": "å…¬å¸B", "type": "æŽ§è‚¡"}}
            ]
        }}
        
        æ³¨æ„ï¼šåªæå–æ˜Žç¡®çš„æŽ§è‚¡å…³ç³»ï¼ŒåŒ…æ‹¬"æŽ§è‚¡"ã€"æŒè‚¡"ã€"æŠ•èµ„"ç­‰å…³ç³»ã€‚
        """
        
        try:
            response = await self.llm_json.ainvoke(prompt)
            result = json.loads(response.content)
            
            relationships = []
            for rel in result.get("relationships", []):
                relationships.append((rel["source"], rel["target"]))
            
            return relationships
        except Exception as e:
            logger.error(f"å…³ç³»æå–å¤±è´¥: {e}")
            return []
    
    def extract_keywords(self, text: str) -> List[str]:
        """ä½¿ç”¨jiebaæå–å…³é”®è¯"""
        # ä½¿ç”¨TF-IDFæå–å…³é”®è¯
        keywords = jieba.analyse.extract_tags(text, topK=10, withWeight=False)
        
        # æ·»åŠ åŸºç¡€åˆ†è¯
        words = jieba.cut(text)
        basic_words = [w for w in words if len(w) > 1 and w.isalnum()]
        
        # åˆå¹¶å¹¶åŽ»é‡
        all_keywords = list(set(keywords + basic_words))
        return all_keywords
    
    def add_documents(self, documents: List[Dict[str, Any]]):
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“"""
        for doc_data in documents:
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                id=doc_data['id'],
                content=doc_data['content'],
                metadata=doc_data['metadata']
            )
            
            # ç”Ÿæˆå‘é‡
            doc.embedding = self.embedding_model.encode(doc.content)
            
            # æå–å…³é”®è¯å¹¶å»ºç«‹ç´¢å¼•
            keywords = self.extract_keywords(doc.content)
            self.keyword_index['doc_terms'][doc.id] = keywords
            
            for keyword in keywords:
                if keyword not in self.keyword_index['terms']:
                    self.keyword_index['terms'][keyword] = []
                self.keyword_index['terms'][keyword].append(len(self.documents))
            
            self.documents.append(doc)
        
        logger.info(f"æ·»åŠ äº† {len(documents)} ä¸ªæ–‡æ¡£åˆ°æ£€ç´¢åº“")
    
    def vector_search(self, query: str, top_k: int = 10) -> List[RetrievalResult]:
        """
        æ”¹è¿›çš„å‘é‡æ£€ç´¢ï¼šä½¿ç”¨æ›´å¥½çš„ç›¸ä¼¼åº¦è®¡ç®—
        """
        if not self.documents:
            return []
        
        # æŸ¥è¯¢å‘é‡åŒ–
        query_embedding = self.embedding_model.encode(query)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        doc_embeddings = np.array([doc.embedding for doc in self.documents])
        similarities = cosine_similarity([query_embedding], doc_embeddings)[0]
        
        # ä½¿ç”¨æ›´ä½Žçš„é˜ˆå€¼ï¼Œæå‡å¬å›žçŽ‡
        results = []
        for i, score in enumerate(similarities):
            if score > self.config['confidence_threshold']:
                results.append(RetrievalResult(
                    document=self.documents[i],
                    score=float(score),
                    source='vector'
                ))
        
        # æŒ‰åˆ†æ•°æŽ’åº
        results.sort(key=lambda x: x.score, reverse=True)
        logger.info(f"å‘é‡æ£€ç´¢: {len(results)} ä¸ªç»“æžœ")
        return results[:top_k]
    
    def keyword_search(self, query: str, top_k: int = 10) -> List[RetrievalResult]:
        """
        æ”¹è¿›çš„å…³é”®è¯æ£€ç´¢ï¼šä½¿ç”¨jiebaåˆ†è¯å’Œæ›´çµæ´»çš„åŒ¹é…
        """
        if not self.documents:
            return []
        
        # æå–æŸ¥è¯¢å…³é”®è¯
        query_keywords = self.extract_keywords(query)
        
        results = []
        for i, doc in enumerate(self.documents):
            doc_keywords = self.keyword_index['doc_terms'].get(doc.id, [])
            
            # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
            if query_keywords and doc_keywords:
                intersection = set(query_keywords).intersection(set(doc_keywords))
                union = set(query_keywords).union(set(doc_keywords))
                
                if intersection:
                    # Jaccardç›¸ä¼¼åº¦
                    jaccard_score = len(intersection) / len(union)
                    
                    # è€ƒè™‘å…³é”®è¯åœ¨æ–‡æ¡£ä¸­çš„é‡è¦æ€§
                    importance_score = len(intersection) / len(query_keywords)
                    
                    # ç»¼åˆåˆ†æ•°
                    final_score = (jaccard_score + importance_score) / 2
                    
                    if final_score > self.config['keyword_threshold']:
                        results.append(RetrievalResult(
                            document=doc,
                            score=final_score,
                            source='keyword'
                        ))
        
        # æŒ‰åˆ†æ•°æŽ’åº
        results.sort(key=lambda x: x.score, reverse=True)
        logger.info(f"å…³é”®è¯æ£€ç´¢: {len(results)} ä¸ªç»“æžœ")
        return results[:top_k]
    
    async def extract_entities_from_query(self, query: str) -> List[Entity]:
        """
        æ”¹è¿›çš„å®žä½“æå–
        """
        prompt = f"""
        ä»Žé—®é¢˜ä¸­æå–æ‰€æœ‰ç›¸å…³çš„å®žä½“ï¼ˆå…¬å¸åã€äººåç­‰ï¼‰ï¼š
        
        é—®é¢˜ï¼š{query}
        
        è¿”å›žJSONæ ¼å¼ï¼š
        {{
            "entities": [
                {{"name": "å®žä½“å", "type": "Company|Person", "confidence": 0.9}}
            ]
        }}
        
        æ³¨æ„ï¼šå°½å¯èƒ½æå–æ‰€æœ‰å¯èƒ½ç›¸å…³çš„å®žä½“ï¼ŒåŒ…æ‹¬ç®€ç§°å’Œå…¨ç§°ã€‚
        """
        
        try:
            response = await self.llm_json.ainvoke(prompt)
            result = json.loads(response.content)
            
            entities = []
            for e in result.get("entities", []):
                entities.append(Entity(
                    name=e["name"],
                    type=e["type"],
                    confidence=e.get("confidence", 0.8)
                ))
            
            logger.info(f"æå–åˆ° {len(entities)} ä¸ªå®žä½“")
            return entities
        except Exception as e:
            logger.error(f"å®žä½“æå–å¤±è´¥: {e}")
            return []
    
    def graph_reasoning(self, entities: List[Entity], query: str) -> GraphResult:
        """
        æ”¹è¿›çš„å›¾è°±æŽ¨ç†ï¼šæ”¯æŒå¤šè·³æŸ¥è¯¢å’Œæ›´çµæ´»çš„åŒ¹é…
        """
        if not entities:
            return GraphResult([], [], 0.0, [])
        
        entity_names = [e.name for e in entities]
        
        # æž„å»ºæ›´çµæ´»çš„æŸ¥è¯¢ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…
        cypher_queries = []
        
        # 1. ç›´æŽ¥å…³ç³»æŸ¥è¯¢
        for entity in entity_names:
            cypher_queries.append(f"""
                MATCH (a)-[r]->(b)
                WHERE a.name CONTAINS '{entity}' OR b.name CONTAINS '{entity}'
                RETURN a.name as source, type(r) as relation, b.name as target, 1.0 as confidence
            """)
        
        # 2. å¤šè·³å…³ç³»æŸ¥è¯¢ï¼ˆ2è·³ï¼‰
        for entity in entity_names:
            cypher_queries.append(f"""
                MATCH (a)-[r1]->(b)-[r2]->(c)
                WHERE a.name CONTAINS '{entity}' OR c.name CONTAINS '{entity}'
                RETURN a.name as source, type(r1) + '->' + type(r2) as relation, c.name as target, 0.8 as confidence
            """)
        
        all_relationships = []
        reasoning_paths = []
        
        with self.driver.session() as session:
            for cypher in cypher_queries:
                try:
                    result = session.run(cypher)
                    for record in result:
                        relationship = {
                            'source': record['source'],
                            'relation': record['relation'],
                            'target': record['target'],
                            'confidence': record['confidence']
                        }
                        all_relationships.append(relationship)
                        reasoning_paths.append(f"{record['source']} -> {record['relation']} -> {record['target']}")
                except Exception as e:
                    logger.error(f"å›¾è°±æŸ¥è¯¢å¤±è´¥: {e}")
        
        # åŽ»é‡
        unique_relationships = []
        seen = set()
        for rel in all_relationships:
            key = (rel['source'], rel['relation'], rel['target'])
            if key not in seen:
                seen.add(key)
                unique_relationships.append(rel)
        
        # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
        if unique_relationships:
            avg_confidence = sum(r['confidence'] for r in unique_relationships) / len(unique_relationships)
        else:
            avg_confidence = 0.0
        
        logger.info(f"å›¾è°±æŽ¨ç†: {len(unique_relationships)} ä¸ªå…³ç³»")
        
        return GraphResult(
            entities=entity_names,
            relationships=unique_relationships,
            confidence=avg_confidence,
            reasoning_path=reasoning_paths
        )
    
    def test_vector_similarity(self, query: str, documents: List[str]) -> Dict[str, Any]:
        """
        æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦è®¡ç®—ï¼Œç”¨äºŽè°ƒè¯•å’Œä¼˜åŒ–
        """
        query_embedding = self.embedding_model.encode(query)
        doc_embeddings = [self.embedding_model.encode(doc) for doc in documents]
        
        similarities = []
        for i, doc_embedding in enumerate(doc_embeddings):
            similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]
            similarities.append({
                'document_index': i,
                'document_preview': documents[i][:100] + "..." if len(documents[i]) > 100 else documents[i],
                'similarity_score': float(similarity)
            })
        
        # æŽ’åº
        similarities.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        return {
            'query': query,
            'similarities': similarities,
            'threshold': self.config['confidence_threshold']
        }
    
    def calculate_joint_score(self, vector_results: List[RetrievalResult], 
                            keyword_results: List[RetrievalResult],
                            graph_result: GraphResult) -> Dict[str, Any]:
        """
        æ”¹è¿›çš„è”åˆè¯„åˆ†æœºåˆ¶
        """
        # æ”¶é›†æ‰€æœ‰æ–‡æ¡£
        all_docs = {}
        
        # å‘é‡æ£€ç´¢ç»“æžœ
        for result in vector_results:
            doc_id = result.document.id
            if doc_id not in all_docs:
                all_docs[doc_id] = {
                    'document': result.document,
                    'vector_score': 0.0,
                    'keyword_score': 0.0,
                    'graph_score': 0.0
                }
            all_docs[doc_id]['vector_score'] = result.score
        
        # å…³é”®è¯æ£€ç´¢ç»“æžœ
        for result in keyword_results:
            doc_id = result.document.id
            if doc_id not in all_docs:
                all_docs[doc_id] = {
                    'document': result.document,
                    'vector_score': 0.0,
                    'keyword_score': 0.0,
                    'graph_score': 0.0
                }
            all_docs[doc_id]['keyword_score'] = result.score
        
        # å›¾è°±æŽ¨ç†åˆ†æ•°ï¼ˆåŸºäºŽæ–‡æ¡£å†…å®¹ä¸Žå›¾è°±å…³ç³»çš„åŒ¹é…åº¦ï¼‰
        graph_confidence = graph_result.confidence
        for doc_id in all_docs:
            # ç®€å•çš„å›¾è°±ç›¸å…³æ€§è¯„åˆ†
            all_docs[doc_id]['graph_score'] = graph_confidence
        
        # è®¡ç®—ç»¼åˆåˆ†æ•°
        final_results = []
        for doc_id, scores in all_docs.items():
            joint_score = (
                scores['vector_score'] * self.config['vector_weight'] +
                scores['keyword_score'] * self.config['keyword_weight'] +
                scores['graph_score'] * self.config['graph_weight']
            )
            
            final_results.append({
                'document': scores['document'],
                'joint_score': joint_score,
                'vector_score': scores['vector_score'],
                'keyword_score': scores['keyword_score'],
                'graph_score': scores['graph_score']
            })
        
        # æŽ’åº
        final_results.sort(key=lambda x: x['joint_score'], reverse=True)
        
        # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
        if final_results:
            max_score = final_results[0]['joint_score']
            overall_confidence = min(max_score, 1.0)
        else:
            overall_confidence = 0.0
        
        return {
            'results': final_results,
            'overall_confidence': overall_confidence,
            'vector_count': len(vector_results),
            'keyword_count': len(keyword_results),
            'graph_confidence': graph_result.confidence
        }
    
    def error_propagation_guard(self, results: Dict[str, Any], 
                              vector_results: List[RetrievalResult],
                              graph_result: GraphResult) -> Dict[str, Any]:
        """
        æ”¹è¿›çš„é”™è¯¯ä¼ æ’­é˜²æŠ¤
        """
        warnings = []
        
        # æ£€æŸ¥æ•´ä½“ç½®ä¿¡åº¦
        if results['overall_confidence'] < self.config['error_propagation_threshold']:
            warnings.append("æ•´ä½“ç½®ä¿¡åº¦è¿‡ä½Žï¼Œå¯èƒ½å­˜åœ¨é”™è¯¯ä¼ æ’­é£Žé™©")
        
        # æ£€æŸ¥å„æ¨¡å—ç½®ä¿¡åº¦
        if not vector_results:
            warnings.append("å‘é‡æ£€ç´¢æ— ç»“æžœï¼Œå»ºè®®æ£€æŸ¥embeddingè´¨é‡")
        
        if results['keyword_count'] == 0:
            warnings.append("å…³é”®è¯æ£€ç´¢æ— ç»“æžœï¼Œå»ºè®®ä¼˜åŒ–åˆ†è¯ç­–ç•¥")
        
        if graph_result.confidence < 0.3:
            warnings.append("å›¾è°±æŽ¨ç†ç½®ä¿¡åº¦è¿‡ä½Žï¼Œå»ºè®®äººå·¥éªŒè¯")
        
        # ç½®ä¿¡åº¦ç­‰çº§
        confidence = results['overall_confidence']
        if confidence >= 0.7:
            confidence_level = "high"
        elif confidence >= 0.4:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        return {
            **results,
            'confidence_level': confidence_level,
            'warnings': warnings
        }
    
    async def multi_hop_qa(self, question: str) -> Dict[str, Any]:
        """
        æ”¹è¿›çš„å¤šè·³é—®ç­”
        """
        logger.info(f"å¼€å§‹å¤„ç†é—®é¢˜: {question}")
        
        # 1. å®žä½“æå–
        entities = await self.extract_entities_from_query(question)
        
        # 2. å¤šæºæ£€ç´¢
        vector_results = self.vector_search(question, top_k=self.config['max_retrieval_results'])
        keyword_results = self.keyword_search(question, top_k=self.config['max_retrieval_results'])
        graph_result = self.graph_reasoning(entities, question)
        
        # 3. è”åˆè¯„åˆ†
        scoring_results = self.calculate_joint_score(vector_results, keyword_results, graph_result)
        
        # 4. é”™è¯¯ä¼ æ’­é˜²æŠ¤
        final_results = self.error_propagation_guard(scoring_results, vector_results, graph_result)
        
        # 5. ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        final_answer = await self.generate_final_answer(
            question, vector_results, keyword_results, graph_result, final_results
        )
        
        return {
            'question': question,
            'answer': final_answer,
            'confidence': final_results['overall_confidence'],
            'confidence_level': final_results['confidence_level'],
            'warnings': final_results['warnings'],
            'vector_count': len(vector_results),
            'keyword_count': len(keyword_results),
            'graph_relationships': len(graph_result.relationships)
        }
    
    async def generate_final_answer(self, question: str, 
                                  vector_results: List[RetrievalResult],
                                  keyword_results: List[RetrievalResult], 
                                  graph_result: GraphResult,
                                  scoring_results: Dict[str, Any]) -> str:
        """
        æ”¹è¿›çš„ç­”æ¡ˆç”Ÿæˆ
        """
        # æ”¶é›†ä¸Šä¸‹æ–‡
        contexts = []
        
        # å‘é‡æ£€ç´¢ä¸Šä¸‹æ–‡
        for result in vector_results[:3]:  # å–å‰3ä¸ª
            contexts.append(f"æ–‡æ¡£å†…å®¹: {result.document.content}")
        
        # å›¾è°±æŽ¨ç†ä¸Šä¸‹æ–‡
        if graph_result.relationships:
            graph_context = "å›¾è°±å…³ç³»:\n"
            for rel in graph_result.relationships[:5]:  # å–å‰5ä¸ªå…³ç³»
                graph_context += f"- {rel['source']} {rel['relation']} {rel['target']}\n"
            contexts.append(graph_context)
        
        context_text = "\n\n".join(contexts)
        
        prompt = f"""
        åŸºäºŽä»¥ä¸‹ä¿¡æ¯å›žç­”é—®é¢˜ï¼š
        
        é—®é¢˜ï¼š{question}
        
        ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
        {context_text}
        
        è¯·æ ¹æ®æä¾›çš„ä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„ç­”æ¡ˆã€‚å¦‚æžœä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯´æ˜Žä¸ç¡®å®šæ€§ã€‚
        """
        
        try:
            response = await self.llm_text.ainvoke(prompt)
            return response.content
        except Exception as e:
            logger.error(f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæ— æ³•ç”Ÿæˆç­”æ¡ˆã€‚"

# æµ‹è¯•å’Œæ¼”ç¤ºå‡½æ•°
async def demo_improved():
    """æ”¹è¿›ç‰ˆæœ¬çš„æ¼”ç¤º"""
    # Neo4jè¿žæŽ¥
    driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))
    
    # LLMé…ç½®
    llm_json = OpenAILLM(
        model_name="gpt-4o-mini",
        model_params={"response_format": {"type": "json_object"}}
    )
    llm_text = OpenAILLM(model_name="gpt-4o-mini")
    
    # åˆ›å»ºæ”¹è¿›çš„ç³»ç»Ÿ
    system = ImprovedHybridRAGSystem(driver, llm_json, llm_text, use_qwen_embedding=True)
    
    # æ¸…ç†æ•°æ®åº“
    system.clear_all_databases()
    
    # åŠ è½½æ•°æ®
    raw_text = system.load_data_from_file("company.txt")
    
    # å¤„ç†æ–‡æ¡£
    documents = await system.process_text_to_documents(raw_text)
    system.add_documents(documents)
    print(f"âœ… æˆåŠŸæ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“")
    
    # æž„å»ºå›¾è°±
    print("ðŸ”— æå–æŽ§è‚¡å…³ç³»å¹¶æž„å»ºçŸ¥è¯†å›¾è°±...")
    relationships = await system.extract_relationships_from_text(raw_text)
    await build_sample_graph_from_relationships(driver, relationships)
    print(f"âœ… æˆåŠŸæž„å»ºåŒ…å« {len(relationships)} ä¸ªå…³ç³»çš„çŸ¥è¯†å›¾è°±")
    
    # æµ‹è¯•é—®é¢˜
    questions = [
        "Aé›†å›¢çš„æœ€å¤§è‚¡ä¸œæ˜¯è°ï¼Ÿ",
        "Bèµ„æœ¬æŽ§åˆ¶å“ªäº›å…¬å¸ï¼Ÿ", 
        "Aé›†å›¢æœ‰å¤šå°‘å±‚çº§çš„æŽ§è‚¡å…³ç³»ï¼Ÿ"
    ]
    
    for question in questions:
        print(f"\nðŸ“‹ é—®é¢˜: {question}")
        print("-" * 40)
        
        result = await system.multi_hop_qa(question)
        
        print(f"ðŸŽ¯ æœ€ç»ˆç­”æ¡ˆ: {result['answer']}")
        print(f"ðŸ“Š æ•´ä½“ç½®ä¿¡åº¦: {result['confidence']:.2f} ({result['confidence_level']})")
        
        if result['warnings']:
            print(f"âš ï¸  è­¦å‘Š: {'; '.join(result['warnings'])}")
        
        print(f"ðŸ” æ£€ç´¢åˆ° {result['vector_count']} ä¸ªå‘é‡ç»“æžœ")
        print(f"ðŸ”— å›¾è°±æŽ¨ç†æ‰¾åˆ° {result['graph_relationships']} ä¸ªå…³ç³»")
    
    # å‘é‡ç›¸ä¼¼åº¦æµ‹è¯•
    print("\nðŸ§ª å‘é‡ç›¸ä¼¼åº¦æµ‹è¯•:")
    test_docs = [doc['content'] for doc in documents[:5]]
    similarity_test = system.test_vector_similarity("Bèµ„æœ¬æŽ§åˆ¶å“ªäº›å…¬å¸", test_docs)
    
    print(f"æŸ¥è¯¢: {similarity_test['query']}")
    print(f"é˜ˆå€¼: {similarity_test['threshold']}")
    for sim in similarity_test['similarities'][:3]:
        print(f"  ç›¸ä¼¼åº¦ {sim['similarity_score']:.3f}: {sim['document_preview']}")
    
    driver.close()

async def build_sample_graph_from_relationships(driver, relationships: List[Tuple[str, str]]):
    """ä»Žå…³ç³»åˆ—è¡¨æž„å»ºå›¾è°±"""
    with driver.session() as session:
        for source, target in relationships:
            session.run("""
                MERGE (a:Company {name: $source})
                MERGE (b:Company {name: $target})
                MERGE (a)-[:CONTROLS]->(b)
            """, source=source, target=target)

if __name__ == "__main__":
    asyncio.run(demo_improved())