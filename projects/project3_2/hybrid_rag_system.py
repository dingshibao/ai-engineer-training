"""
æ··åˆRAGç³»ç»Ÿä¸»å…¥å£
åŒ…å«å®Œæ•´çš„æ··åˆRAGç³»ç»Ÿå®ç°å’Œæ¼”ç¤ºåŠŸèƒ½
"""

import asyncio
import json
import logging
import numpy as np
import os
import dashscope
import requests
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional, Any
from neo4j import GraphDatabase
from neo4j_graphrag.llm import OpenAILLM
import re
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import jieba
import jieba.analyse

# å¯¼å…¥æ¨¡å‹å®šä¹‰
from models import Entity, Relationship, Document, RetrievalResult, GraphResult
from embedding import QwenEmbedding

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è®¾ç½®APIå¯†é’¥
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY", "your-api-key-here")

class ImprovedHybridRAGSystem:
    """
    æ”¹è¿›çš„æ··åˆRAGç³»ç»Ÿ
    
    ä¸»è¦æ”¹è¿›ï¼š
    1. ä½¿ç”¨é€šä¹‰åƒé—®text-embedding-v3æå‡ä¸­æ–‡ç†è§£
    2. ä¼˜åŒ–å…³é”®è¯æå–ï¼Œä½¿ç”¨jiebaåˆ†è¯
    3. æ”¹è¿›ç›¸ä¼¼åº¦è®¡ç®—å’Œé˜ˆå€¼è®¾ç½®
    4. å¢å¼ºå›¾è°±æ¨ç†é€»è¾‘
    5. æ·»åŠ å‘é‡æ•°æ®åº“å†…ç½®å‡½æ•°å¯¹æ¯”æµ‹è¯•
    """
    
    def __init__(self, neo4j_driver, llm_json, llm_text, use_qwen_embedding=True):
        self.driver = neo4j_driver
        self.llm_json = llm_json  # ç»“æ„åŒ–è¾“å‡º
        self.llm_text = llm_text  # æ–‡æœ¬ç”Ÿæˆ
        
        # åˆå§‹åŒ–å‘é‡æ¨¡å‹
        if use_qwen_embedding:
            self.embedding_model = QwenEmbedding("text-embedding-v3")
            logger.info("âœ… ä½¿ç”¨é€šä¹‰åƒé—®text-embedding-v3æ¨¡å‹")
        else:
            self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("âœ… ä½¿ç”¨SentenceTransformeræ¨¡å‹")
        
        # æ–‡æ¡£å­˜å‚¨
        self.documents: List[Document] = []
        
        # å…³é”®è¯ç´¢å¼•
        self.keyword_index = {
            'terms': {},  # term -> [doc_indices]
            'doc_terms': {}  # doc_id -> [terms]
        }
        
        # é…ç½®å‚æ•° - é™ä½é˜ˆå€¼æå‡å¬å›ç‡
        self.config = {
            'confidence_threshold': 0.3,  # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
            'max_retrieval_results': 10,   # å¢åŠ æ£€ç´¢ç»“æœæ•°
            'vector_weight': 0.5,         # æé«˜å‘é‡æ£€ç´¢æƒé‡
            'keyword_weight': 0.3,        # å…³é”®è¯æ£€ç´¢æƒé‡  
            'graph_weight': 0.2,          # å›¾è°±æ¨ç†æƒé‡
            'error_propagation_threshold': 0.3,  # é™ä½é”™è¯¯ä¼ æ’­é˜ˆå€¼
            'keyword_threshold': 0.1      # å…³é”®è¯åŒ¹é…é˜ˆå€¼
        }
    
    def clear_vector_database(self):
        """æ¸…ç†å‘é‡æ•°æ®åº“ï¼Œåˆ é™¤æ‰€æœ‰æ–‡æ¡£å’ŒåµŒå…¥"""
        self.documents = []
        self.keyword_index = {
            'terms': {},  # term -> [doc_indices]
            'doc_terms': {}  # doc_id -> [terms]
        }
        logger.info("âœ… å‘é‡æ•°æ®åº“å·²æ¸…ç†")
    
    def clear_graph_database(self):
        """æ¸…ç†å›¾æ•°æ®åº“ï¼Œåˆ é™¤æ‰€æœ‰èŠ‚ç‚¹å’Œå…³ç³»"""
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
        logger.info("âœ… å›¾æ•°æ®åº“å·²æ¸…ç†")
    
    def clear_all_databases(self):
        """æ¸…ç†æ‰€æœ‰æ•°æ®åº“"""
        self.clear_vector_database()
        self.clear_graph_database()
        logger.info("ğŸ§¹ æ‰€æœ‰æ•°æ®åº“å·²æ¸…ç†å®Œæˆ")
    
    def load_data_from_file(self, file_path: str) -> str:
        """ä»æ–‡ä»¶åŠ è½½æ•°æ®"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
            return ""
    
    async def process_text_to_documents(self, raw_text: str) -> List[Dict[str, Any]]:
        """å°†åŸå§‹æ–‡æœ¬å¤„ç†ä¸ºæ–‡æ¡£"""
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = [p.strip() for p in raw_text.split('\n') if p.strip()]
        
        documents = []
        for i, paragraph in enumerate(paragraphs):
            if len(paragraph) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„æ®µè½
                documents.append({
                    'id': f'doc_{i}',
                    'content': paragraph,
                    'metadata': {'source': 'file', 'paragraph_id': i}
                })
        
        return documents
    
    async def extract_relationships_from_text(self, raw_text: str) -> List[Tuple[str, str]]:
        """ä»æ–‡æœ¬ä¸­æå–å…³ç³»"""
        prompt = f"""
        ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…¬å¸æ§è‚¡å…³ç³»ï¼Œè¿”å›JSONæ ¼å¼ï¼š
        
        æ–‡æœ¬ï¼š{raw_text}
        
        è¿”å›æ ¼å¼ï¼š
        {{
            "relationships": [
                {{"source": "å…¬å¸A", "target": "å…¬å¸B", "type": "æ§è‚¡"}}
            ]
        }}
        
        æ³¨æ„ï¼šåªæå–æ˜ç¡®çš„æ§è‚¡å…³ç³»ï¼ŒåŒ…æ‹¬"æ§è‚¡"ã€"æŒè‚¡"ã€"æŠ•èµ„"ç­‰å…³ç³»ã€‚
        """
        
        try:
            response = await self.llm_json.ainvoke(prompt)
            result = json.loads(response.content)
            
            relationships = []
            for rel in result.get("relationships", []):
                relationships.append((rel["source"], rel["target"]))
            
            return relationships
        except Exception as e:
            logger.error(f"å…³ç³»æå–å¤±è´¥: {e}")
            return []
    
    def extract_keywords(self, text: str) -> List[str]:
        """ä½¿ç”¨jiebaæå–å…³é”®è¯"""
        # ä½¿ç”¨TF-IDFæå–å…³é”®è¯
        keywords = jieba.analyse.extract_tags(text, topK=10, withWeight=False)
        
        # æ·»åŠ åŸºç¡€åˆ†è¯
        words = jieba.cut(text)
        basic_words = [w for w in words if len(w) > 1 and w.isalnum()]
        
        # åˆå¹¶å¹¶å»é‡
        all_keywords = list(set(keywords + basic_words))
        return all_keywords
    
    def add_documents(self, documents: List[Dict[str, Any]]):
        """æ·»åŠ æ–‡æ¡£åˆ°å‘é‡æ•°æ®åº“"""
        for doc_data in documents:
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc = Document(
                id=doc_data['id'],
                content=doc_data['content'],
                metadata=doc_data['metadata']
            )
            
            # ç”Ÿæˆå‘é‡
            doc.embedding = self.embedding_model.encode(doc.content)
            
            # æå–å…³é”®è¯å¹¶å»ºç«‹ç´¢å¼•
            keywords = self.extract_keywords(doc.content)
            self.keyword_index['doc_terms'][doc.id] = keywords
            
            for keyword in keywords:
                if keyword not in self.keyword_index['terms']:
                    self.keyword_index['terms'][keyword] = []
                self.keyword_index['terms'][keyword].append(len(self.documents))
            
            self.documents.append(doc)
        
        logger.info(f"æ·»åŠ äº† {len(documents)} ä¸ªæ–‡æ¡£åˆ°æ£€ç´¢åº“")
    
    def vector_search(self, query: str, top_k: int = 10) -> List[RetrievalResult]:
        """
        æ”¹è¿›çš„å‘é‡æ£€ç´¢ï¼šä½¿ç”¨æ›´å¥½çš„ç›¸ä¼¼åº¦è®¡ç®—
        """
        if not self.documents:
            return []
        
        # æŸ¥è¯¢å‘é‡åŒ–
        query_embedding = self.embedding_model.encode(query)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        doc_embeddings = np.array([doc.embedding for doc in self.documents])
        similarities = cosine_similarity([query_embedding], doc_embeddings)[0]
        
        # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼ï¼Œæå‡å¬å›ç‡
        results = []
        for i, score in enumerate(similarities):
            if score > self.config['confidence_threshold']:
                results.append(RetrievalResult(
                    document=self.documents[i],
                    score=float(score),
                    source='vector'
                ))
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x.score, reverse=True)
        logger.info(f"å‘é‡æ£€ç´¢: {len(results)} ä¸ªç»“æœ")
        return results[:top_k]
    
    def keyword_search(self, query: str, top_k: int = 10) -> List[RetrievalResult]:
        """
        æ”¹è¿›çš„å…³é”®è¯æ£€ç´¢ï¼šä½¿ç”¨jiebaåˆ†è¯å’Œæ›´çµæ´»çš„åŒ¹é…
        """
        if not self.documents:
            return []
        
        # æå–æŸ¥è¯¢å…³é”®è¯
        query_keywords = self.extract_keywords(query)
        
        results = []
        for i, doc in enumerate(self.documents):
            doc_keywords = self.keyword_index['doc_terms'].get(doc.id, [])
            
            # è®¡ç®—å…³é”®è¯åŒ¹é…åº¦
            if query_keywords and doc_keywords:
                intersection = set(query_keywords).intersection(set(doc_keywords))
                union = set(query_keywords).union(set(doc_keywords))
                
                # Jaccardç›¸ä¼¼åº¦
                jaccard_score = len(intersection) / len(union) if union else 0
                
                # é‡è¦æ€§åŠ æƒ
                importance_score = len(intersection) / len(query_keywords) if query_keywords else 0
                
                # ç»¼åˆåˆ†æ•°
                final_score = (jaccard_score + importance_score) / 2
                
                if final_score > self.config['keyword_threshold']:
                    results.append(RetrievalResult(
                        document=doc,
                        score=final_score,
                        source='keyword'
                    ))
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x.score, reverse=True)
        logger.info(f"å…³é”®è¯æ£€ç´¢: {len(results)} ä¸ªç»“æœ")
        return results[:top_k]
    
    async def extract_entities_from_query(self, query: str) -> List[Entity]:
        """ä»æŸ¥è¯¢ä¸­æå–å®ä½“"""
        prompt = f"""
        ä»ä»¥ä¸‹æŸ¥è¯¢ä¸­æå–å…¬å¸å®ä½“ï¼Œè¿”å›JSONæ ¼å¼ï¼š
        
        æŸ¥è¯¢ï¼š{query}
        
        è¿”å›æ ¼å¼ï¼š
        {{
            "entities": [
                {{"name": "å…¬å¸åç§°", "type": "å…¬å¸", "confidence": 0.9}}
            ]
        }}
        
        æ³¨æ„ï¼šåªæå–æ˜ç¡®çš„å…¬å¸åç§°å®ä½“ã€‚
        """
        
        try:
            response = await self.llm_json.ainvoke(prompt)
            result = json.loads(response.content)
            
            entities = []
            for ent in result.get("entities", []):
                entities.append(Entity(
                    name=ent["name"],
                    type=ent["type"],
                    confidence=ent["confidence"]
                ))
            
            return entities
        except Exception as e:
            logger.error(f"å®ä½“æå–å¤±è´¥: {e}")
            return []
    
    def graph_reasoning(self, entities: List[Entity], query: str) -> GraphResult:
        """
        æ”¹è¿›çš„å›¾è°±æ¨ç†ï¼šæ”¯æŒå¤šè·³æŸ¥è¯¢å’Œæ›´çµæ´»çš„åŒ¹é…
        """
        if not entities:
            return GraphResult([], [], 0.0, [])
        
        entity_names = [e.name for e in entities]
        
        # æ„å»ºæ›´çµæ´»çš„æŸ¥è¯¢ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…
        cypher_queries = []
        
        # 1. ç›´æ¥å…³ç³»æŸ¥è¯¢
        for entity in entity_names:
            cypher_queries.append(f"""
                MATCH (a)-[r]->(b)
                WHERE a.name CONTAINS '{entity}' OR b.name CONTAINS '{entity}'
                RETURN a.name as source, type(r) as relation, b.name as target, 1.0 as confidence
            """)
        
        # 2. å¤šè·³å…³ç³»æŸ¥è¯¢ï¼ˆ2è·³ï¼‰
        for entity in entity_names:
            cypher_queries.append(f"""
                MATCH (a)-[r1]->(b)-[r2]->(c)
                WHERE a.name CONTAINS '{entity}' OR c.name CONTAINS '{entity}'
                RETURN a.name as source, type(r1) + '->' + type(r2) as relation, c.name as target, 0.8 as confidence
            """)
        
        all_relationships = []
        reasoning_paths = []
        
        with self.driver.session() as session:
            for cypher in cypher_queries:
                try:
                    result = session.run(cypher)
                    for record in result:
                        relationship = {
                            'source': record['source'],
                            'relation': record['relation'],
                            'target': record['target'],
                            'confidence': record['confidence']
                        }
                        all_relationships.append(relationship)
                        reasoning_paths.append(f"{record['source']} -> {record['relation']} -> {record['target']}")
                except Exception as e:
                    logger.error(f"å›¾è°±æŸ¥è¯¢å¤±è´¥: {e}")
        
        # å»é‡
        unique_relationships = []
        seen = set()
        for rel in all_relationships:
            key = (rel['source'], rel['relation'], rel['target'])
            if key not in seen:
                seen.add(key)
                unique_relationships.append(rel)
        
        # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
        if unique_relationships:
            avg_confidence = sum(r['confidence'] for r in unique_relationships) / len(unique_relationships)
        else:
            avg_confidence = 0.0
        
        logger.info(f"å›¾è°±æ¨ç†: {len(unique_relationships)} ä¸ªå…³ç³»")
        
        return GraphResult(
            entities=entity_names,
            relationships=unique_relationships,
            confidence=avg_confidence,
            reasoning_path=reasoning_paths
        )
    
    def test_vector_similarity(self, query: str, documents: List[str]) -> Dict[str, Any]:
        """
        æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦è®¡ç®—ï¼Œç”¨äºè°ƒè¯•å’Œä¼˜åŒ–
        """
        query_embedding = self.embedding_model.encode(query)
        doc_embeddings = [self.embedding_model.encode(doc) for doc in documents]
        
        similarities = []
        for i, doc_embedding in enumerate(doc_embeddings):
            similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]
            similarities.append({
                'document_index': i,
                'document_preview': documents[i][:100] + "..." if len(documents[i]) > 100 else documents[i],
                'similarity_score': float(similarity)
            })
        
        # æ’åº
        similarities.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        return {
            'query': query,
            'similarities': similarities,
            'threshold': self.config['confidence_threshold']
        }
    
    def calculate_joint_score(self, vector_results: List[RetrievalResult], 
                            keyword_results: List[RetrievalResult], 
                            graph_result: GraphResult) -> List[RetrievalResult]:
        """
        è®¡ç®—è”åˆåˆ†æ•°ï¼šç»“åˆå‘é‡ã€å…³é”®è¯å’Œå›¾è°±æ¨ç†ç»“æœ
        """
        # åˆ›å»ºæ–‡æ¡£åˆ†æ•°å­—å…¸
        doc_scores = {}
        
        # å‘é‡æ£€ç´¢åˆ†æ•°
        for result in vector_results:
            doc_id = result.document.id
            doc_scores[doc_id] = doc_scores.get(doc_id, 0) + result.score * self.config['vector_weight']
        
        # å…³é”®è¯æ£€ç´¢åˆ†æ•°
        for result in keyword_results:
            doc_id = result.document.id
            doc_scores[doc_id] = doc_scores.get(doc_id, 0) + result.score * self.config['keyword_weight']
        
        # å›¾è°±æ¨ç†åˆ†æ•°
        if graph_result.confidence > 0:
            # ä¸ºåŒ…å«å›¾è°±å®ä½“çš„æ–‡æ¡£å¢åŠ åˆ†æ•°
            for doc in self.documents:
                for entity in graph_result.entities:
                    if entity.lower() in doc.content.lower():
                        doc_scores[doc.id] = doc_scores.get(doc.id, 0) + graph_result.confidence * self.config['graph_weight']
        
        # è½¬æ¢ä¸ºç»“æœåˆ—è¡¨
        joint_results = []
        for doc_id, score in doc_scores.items():
            doc = next((d for d in self.documents if d.id == doc_id), None)
            if doc:
                joint_results.append(RetrievalResult(
                    document=doc,
                    score=score,
                    source='joint'
                ))
        
        # æ’åº
        joint_results.sort(key=lambda x: x.score, reverse=True)
        return joint_results
    
    def error_propagation_guard(self, results: List[RetrievalResult]) -> List[RetrievalResult]:
        """
        é”™è¯¯ä¼ æ’­é˜²æŠ¤ï¼šè¿‡æ»¤ä½è´¨é‡ç»“æœ
        """
        if not results:
            return results
        
        # è®¡ç®—åˆ†æ•°ç»Ÿè®¡
        scores = [r.score for r in results]
        avg_score = sum(scores) / len(scores)
        
        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
        filtered_results = [
            r for r in results 
            if r.score >= self.config['error_propagation_threshold'] and r.score >= avg_score * 0.5
        ]
        
        logger.info(f"é”™è¯¯ä¼ æ’­é˜²æŠ¤: {len(results)} -> {len(filtered_results)} ä¸ªç»“æœ")
        return filtered_results
    
    async def multi_hop_qa(self, question: str, max_hops: int = 3) -> Dict[str, Any]:
        """
        å¤šè·³é—®ç­”ï¼šç»“åˆå‘é‡æ£€ç´¢ã€å…³é”®è¯åŒ¹é…å’Œå›¾è°±æ¨ç†
        """
        logger.info(f"ğŸ” å¼€å§‹å¤šè·³é—®ç­”: {question}")
        
        # 1. å®ä½“æå–
        entities = await self.extract_entities_from_query(question)
        logger.info(f"æå–åˆ° {len(entities)} ä¸ªå®ä½“")
        
        # 2. å¤šæºæ£€ç´¢
        vector_results = self.vector_search(question, top_k=self.config['max_retrieval_results'])
        keyword_results = self.keyword_search(question, top_k=self.config['max_retrieval_results'])
        graph_result = self.graph_reasoning(entities, question)
        
        # 3. è”åˆè¯„åˆ†
        joint_results = self.calculate_joint_score(vector_results, keyword_results, graph_result)
        
        # 4. é”™è¯¯ä¼ æ’­é˜²æŠ¤
        final_results = self.error_propagation_guard(joint_results)
        
        # 5. ç”Ÿæˆç­”æ¡ˆ
        if final_results:
            context = [r.document.content for r in final_results[:5]]
            answer = self.generate_final_answer(question, context)
        else:
            answer = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
        
        return {
            'question': question,
            'answer': answer,
            'entities': [{'name': e.name, 'type': e.type, 'confidence': e.confidence} for e in entities],
            'vector_results': len(vector_results),
            'keyword_results': len(keyword_results),
            'graph_confidence': graph_result.confidence,
            'final_results': len(final_results),
            'reasoning_path': graph_result.reasoning_path
        }
    
    def generate_final_answer(self, question: str, context: List[str]) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        """
        if not context:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
        
        # æ„å»ºæç¤ºè¯
        context_text = "\n\n".join([f"æ–‡æ¡£{i+1}: {ctx}" for i, ctx in enumerate(context)])
        
        prompt = f"""
        åŸºäºä»¥ä¸‹æ–‡æ¡£ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚è¯·ç¡®ä¿ç­”æ¡ˆå‡†ç¡®ã€å®Œæ•´ï¼Œå¹¶åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹ã€‚

        é—®é¢˜ï¼š{question}

        ç›¸å…³æ–‡æ¡£ï¼š
        {context_text}

        è¯·æä¾›è¯¦ç»†çš„ç­”æ¡ˆï¼š
        """
        
        try:
            # ä½¿ç”¨åŒæ­¥è°ƒç”¨
            if hasattr(self.llm_text, 'invoke'):
                response = self.llm_text.invoke(prompt)
            else:
                # å¦‚æœæ˜¯å¼‚æ­¥LLMï¼Œéœ€è¦åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è°ƒç”¨
                import asyncio
                loop = asyncio.get_event_loop()
                response = loop.run_until_complete(self.llm_text.ainvoke(prompt))
            
            return response.content if hasattr(response, 'content') else str(response)
        except Exception as e:
            logger.error(f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            return f"åŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œæˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹ç›¸å…³å†…å®¹ï¼š\n\n{context_text[:500]}..."


async def demo_improved():
    """æ”¹è¿›ç‰ˆæ¼”ç¤ºå‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨æ”¹è¿›ç‰ˆæ··åˆRAGç³»ç»Ÿæ¼”ç¤º")
    
    # Neo4jè¿æ¥
    driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))
    
    # LLMé…ç½®
    llm_json = OpenAILLM(
        model_name="gpt-4o-mini",
        model_params={
            "response_format": {"type": "json_object"},
            "temperature": 0.0,
        },
    )
    
    llm_text = OpenAILLM(
        model_name="gpt-4o-mini",
        model_params={
            "temperature": 0.3,
        },
    )
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    rag_system = ImprovedHybridRAGSystem(driver, llm_json, llm_text, use_qwen_embedding=True)
    
    try:
        # æ¸…ç†ç°æœ‰æ•°æ®
        rag_system.clear_all_databases()
        
        # åŠ è½½æ•°æ®
        file_path = "d:\\AIå·¥ç¨‹åŒ–è®­ç»ƒè¥\\workspace\\project\\project3_2\\company.txt"
        raw_text = rag_system.load_data_from_file(file_path)
        
        if not raw_text:
            logger.error("âŒ æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶")
            return
        
        # å¤„ç†æ–‡æ¡£
        documents = await rag_system.process_text_to_documents(raw_text)
        rag_system.add_documents(documents)
        
        # ä»æ–‡æœ¬ä¸­æå–å…³ç³»å¹¶æ„å»ºçŸ¥è¯†å›¾è°±
        relationships = await rag_system.extract_relationships_from_text(raw_text)
        await build_sample_graph_from_relationships(driver, relationships)
        
        # æµ‹è¯•é—®ç­”
        questions = [
            "Aé›†å›¢çš„æœ€å¤§è‚¡ä¸œæ˜¯è°ï¼Ÿ",
            "Bèµ„æœ¬æ§åˆ¶å“ªäº›å…¬å¸ï¼Ÿ", 
            "Aé›†å›¢æœ‰å¤šå°‘å±‚çº§çš„æ§è‚¡å…³ç³»ï¼Ÿ"
        ]
        
        for question in questions:
            logger.info(f"\n{'='*50}")
            result = await rag_system.multi_hop_qa(question)
            logger.info(f"é—®é¢˜: {result['question']}")
            logger.info(f"ç­”æ¡ˆ: {result['answer']}")
            logger.info(f"æ£€ç´¢ç»Ÿè®¡: å‘é‡={result['vector_results']}, å…³é”®è¯={result['keyword_results']}, å›¾è°±ç½®ä¿¡åº¦={result['graph_confidence']:.2f}")
        
        # æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦
        test_docs = [doc['content'] for doc in documents[:3]]
        similarity_result = rag_system.test_vector_similarity("Aé›†å›¢", test_docs)
        logger.info(f"\nå‘é‡ç›¸ä¼¼åº¦æµ‹è¯•ç»“æœ: {similarity_result}")
        
    finally:
        # æ¸…ç†èµ„æº
        rag_system.clear_all_databases()
        driver.close()
        logger.info("âœ… ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼Œèµ„æºå·²æ¸…ç†")


async def build_sample_graph_from_relationships(driver, relationships: List[Tuple[str, str]]):
    """æ„å»ºç¤ºä¾‹çŸ¥è¯†å›¾è°±"""
    logger.info("ğŸ”§ å¼€å§‹æ„å»ºç¤ºä¾‹çŸ¥è¯†å›¾è°±...")
    
    with driver.session() as session:
        # æ¸…ç©ºç°æœ‰æ•°æ®
        session.run("MATCH (n) DETACH DELETE n")
        
        # æ·»åŠ å…³ç³»
        for source, target in relationships:
            session.run("""
                MERGE (a:Company {name: $source})
                MERGE (b:Company {name: $target})
                MERGE (a)-[:RELATED_TO]->(b)
            """, source=source, target=target)
    
    logger.info(f"âœ… ç¤ºä¾‹å›¾æ„å»ºå®Œæˆ: {len(relationships)} ä¸ªå…³ç³»")


if __name__ == "__main__":
    asyncio.run(demo_improved())